{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD5uOmKlKDva"
      },
      "source": [
        "# Dims reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BSxKTg49dw_0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_path = '/content/train_dataset_full (1).csv'\n",
        "test_path = '/content/X_test_1st.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "test_data = pd.read_csv(test_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulf4ibb7D6TO",
        "outputId": "a3a8cc02-eba5-4c45-c4c6-028368e373e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.3)\n",
            "Collecting xgboost\n",
            "  Downloading xgboost-2.1.4-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.13.1)\n",
            "Downloading xgboost-2.1.4-py3-none-manylinux_2_28_x86_64.whl (223.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xgboost\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 2.1.3\n",
            "    Uninstalling xgboost-2.1.3:\n",
            "      Successfully uninstalled xgboost-2.1.3\n",
            "Successfully installed xgboost-2.1.4\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.2.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.37)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.0-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.4/383.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.9 alembic-1.14.1 colorlog-6.9.0 optuna-4.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade xgboost\n",
        "!pip install --upgrade sklearn\n",
        "!pip install -- optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "ZWOVCkHy5lsg",
        "outputId": "0b19d1b5-d96f-4d8a-e18f-157da7352548"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-6cab3c10-1051-48c4-950c-3af7fbc858af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session_id</th>\n",
              "      <th>DateTime</th>\n",
              "      <th>user_id</th>\n",
              "      <th>product</th>\n",
              "      <th>campaign_id</th>\n",
              "      <th>webpage_id</th>\n",
              "      <th>product_category_1</th>\n",
              "      <th>product_category_2</th>\n",
              "      <th>user_group_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age_level</th>\n",
              "      <th>user_depth</th>\n",
              "      <th>city_development_index</th>\n",
              "      <th>var_1</th>\n",
              "      <th>is_click</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>98528.0</td>\n",
              "      <td>2017-07-04 16:42</td>\n",
              "      <td>7716.0</td>\n",
              "      <td>C</td>\n",
              "      <td>405490.0</td>\n",
              "      <td>60305.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>589714.0</td>\n",
              "      <td>2017-07-07 07:40</td>\n",
              "      <td>1035283.0</td>\n",
              "      <td>I</td>\n",
              "      <td>118601.0</td>\n",
              "      <td>28529.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>82527.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>478652.0</td>\n",
              "      <td>2017-07-07 20:42</td>\n",
              "      <td>65994.0</td>\n",
              "      <td>H</td>\n",
              "      <td>359520.0</td>\n",
              "      <td>13787.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34536.0</td>\n",
              "      <td>2017-07-05 15:05</td>\n",
              "      <td>75976.0</td>\n",
              "      <td>H</td>\n",
              "      <td>405490.0</td>\n",
              "      <td>60305.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>71863.0</td>\n",
              "      <td>2017-07-06 20:11</td>\n",
              "      <td>987498.0</td>\n",
              "      <td>C</td>\n",
              "      <td>405490.0</td>\n",
              "      <td>60305.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cab3c10-1051-48c4-950c-3af7fbc858af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6cab3c10-1051-48c4-950c-3af7fbc858af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6cab3c10-1051-48c4-950c-3af7fbc858af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7b19f43b-1ce9-4217-8e86-c4c2d14227f4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7b19f43b-1ce9-4217-8e86-c4c2d14227f4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7b19f43b-1ce9-4217-8e86-c4c2d14227f4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   session_id          DateTime    user_id product  campaign_id  webpage_id  \\\n",
              "0     98528.0  2017-07-04 16:42     7716.0       C     405490.0     60305.0   \n",
              "1    589714.0  2017-07-07 07:40  1035283.0       I     118601.0     28529.0   \n",
              "2    478652.0  2017-07-07 20:42    65994.0       H     359520.0     13787.0   \n",
              "3     34536.0  2017-07-05 15:05    75976.0       H     405490.0     60305.0   \n",
              "4     71863.0  2017-07-06 20:11   987498.0       C     405490.0     60305.0   \n",
              "\n",
              "   product_category_1  product_category_2  user_group_id  gender  age_level  \\\n",
              "0                 3.0                 NaN            3.0    Male        3.0   \n",
              "1                 4.0             82527.0           10.0  Female        4.0   \n",
              "2                 4.0                 NaN            4.0    Male        4.0   \n",
              "3                 3.0                 NaN            3.0    Male        3.0   \n",
              "4                 3.0                 NaN            2.0    Male        2.0   \n",
              "\n",
              "   user_depth  city_development_index  var_1  is_click  \n",
              "0         3.0                     NaN    1.0       1.0  \n",
              "1         3.0                     3.0    1.0       0.0  \n",
              "2         3.0                     2.0    0.0       0.0  \n",
              "3         3.0                     3.0    0.0       0.0  \n",
              "4         3.0                     2.0    0.0       0.0  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XiWuG6ksER85",
        "outputId": "d764b6bb-23f3-4397-e799-5e361dbd4a00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-08 19:44:50,721] A new study created in memory with name: no-name-d438b957-f69f-4c84-9bd8-fdeb448f04a5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imbalance Ratio: 13.79824741211438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-08 19:45:46,006] Trial 0 finished with values: [0.09509515162681398, 0.5634506563366933] and parameters: {'max_depth': 7, 'learning_rate': 0.010292061248376264, 'n_estimators': 450, 'subsample': 0.6929472982028031, 'colsample_bytree': 0.615230123556783}.\n",
            "[I 2025-02-08 19:46:24,821] Trial 1 finished with values: [0.09251249016421646, 0.5621454682496738] and parameters: {'max_depth': 5, 'learning_rate': 0.04938057393563638, 'n_estimators': 700, 'subsample': 0.5836179074142844, 'colsample_bytree': 0.5905421051955576}.\n",
            "[I 2025-02-08 19:47:57,152] Trial 2 finished with values: [0.08818866871524682, 0.5473080659328523] and parameters: {'max_depth': 10, 'learning_rate': 0.07140923731626041, 'n_estimators': 900, 'subsample': 0.9023648985772466, 'colsample_bytree': 0.540248722029248}.\n",
            "[I 2025-02-08 19:48:27,697] Trial 3 finished with values: [0.09401856776309823, 0.5620079512688817] and parameters: {'max_depth': 5, 'learning_rate': 0.02462429885488423, 'n_estimators': 550, 'subsample': 0.7742321748278573, 'colsample_bytree': 0.9518035179856283}.\n",
            "[I 2025-02-08 19:48:47,421] Trial 4 finished with values: [0.09322986882953439, 0.5618355775634782] and parameters: {'max_depth': 7, 'learning_rate': 0.04507098361639317, 'n_estimators': 250, 'subsample': 0.6314553161638341, 'colsample_bytree': 0.8117839527730852}.\n",
            "[I 2025-02-08 19:49:08,479] Trial 5 finished with values: [0.0914996702870385, 0.5597427565069039] and parameters: {'max_depth': 4, 'learning_rate': 0.1560584631631982, 'n_estimators': 450, 'subsample': 0.7270751721895052, 'colsample_bytree': 0.6185740400757145}.\n",
            "[I 2025-02-08 19:50:03,182] Trial 6 finished with values: [0.09048279744269377, 0.5572815211715548] and parameters: {'max_depth': 8, 'learning_rate': 0.04056288755538157, 'n_estimators': 650, 'subsample': 0.6559102868973521, 'colsample_bytree': 0.7723302913594127}.\n",
            "[I 2025-02-08 19:50:59,802] Trial 7 finished with values: [0.09306716514756654, 0.5607002686003345] and parameters: {'max_depth': 8, 'learning_rate': 0.016706072080366407, 'n_estimators': 700, 'subsample': 0.7020628478670805, 'colsample_bytree': 0.9804675588470633}.\n",
            "[I 2025-02-08 19:51:13,517] Trial 8 finished with values: [0.09342124004002515, 0.5614851455048092] and parameters: {'max_depth': 8, 'learning_rate': 0.07276840317624979, 'n_estimators': 150, 'subsample': 0.9185592496780162, 'colsample_bytree': 0.7408059621426377}.\n",
            "[I 2025-02-08 19:52:05,711] Trial 9 finished with values: [0.09266574176693983, 0.561240357424435] and parameters: {'max_depth': 6, 'learning_rate': 0.035454710846945015, 'n_estimators': 850, 'subsample': 0.8022986865177791, 'colsample_bytree': 0.6739998400988226}.\n",
            "[I 2025-02-08 19:53:21,152] Trial 10 finished with values: [0.08684919193665601, 0.545603595857703] and parameters: {'max_depth': 8, 'learning_rate': 0.10645470345676099, 'n_estimators': 900, 'subsample': 0.7784732843073631, 'colsample_bytree': 0.7411238693837015}.\n",
            "[I 2025-02-08 19:53:37,058] Trial 11 finished with values: [0.09473143451688039, 0.5640053240975528] and parameters: {'max_depth': 9, 'learning_rate': 0.023925773188120017, 'n_estimators': 150, 'subsample': 0.666692598226888, 'colsample_bytree': 0.5217004195873143}.\n",
            "[I 2025-02-08 19:54:56,555] Trial 12 finished with values: [0.0908626288633732, 0.5526218886251522] and parameters: {'max_depth': 10, 'learning_rate': 0.020991885017621073, 'n_estimators': 750, 'subsample': 0.7638805137149179, 'colsample_bytree': 0.9365521570882179}.\n",
            "[I 2025-02-08 19:56:04,830] Trial 13 finished with values: [0.0942479922796633, 0.5640783142850597] and parameters: {'max_depth': 7, 'learning_rate': 0.012843227340832621, 'n_estimators': 900, 'subsample': 0.6685424992073219, 'colsample_bytree': 0.5521561448740044}.\n",
            "[I 2025-02-08 19:56:17,086] Trial 14 finished with values: [0.09432941134592561, 0.5596178853916746] and parameters: {'max_depth': 5, 'learning_rate': 0.046166237627275765, 'n_estimators': 100, 'subsample': 0.8041303286517842, 'colsample_bytree': 0.6541077823025578}.\n",
            "[I 2025-02-08 19:56:48,092] Trial 15 finished with values: [0.09222053347900028, 0.5602755839943108] and parameters: {'max_depth': 5, 'learning_rate': 0.05492571685487559, 'n_estimators': 550, 'subsample': 0.6267492586424906, 'colsample_bytree': 0.9235088610999277}.\n",
            "[I 2025-02-08 19:57:37,055] Trial 16 finished with values: [0.09269148962993573, 0.5582808721530972] and parameters: {'max_depth': 3, 'learning_rate': 0.11981680431452174, 'n_estimators': 950, 'subsample': 0.9434098656606291, 'colsample_bytree': 0.5484397177636087}.\n",
            "[I 2025-02-08 19:58:08,929] Trial 17 finished with values: [0.09315642212148656, 0.5580688875235368] and parameters: {'max_depth': 3, 'learning_rate': 0.045971762679828054, 'n_estimators': 750, 'subsample': 0.5152051976948705, 'colsample_bytree': 0.6277322247675663}.\n",
            "[I 2025-02-08 19:58:55,707] Trial 18 finished with values: [0.09133567026098655, 0.5572687418194925] and parameters: {'max_depth': 7, 'learning_rate': 0.050049447803137824, 'n_estimators': 700, 'subsample': 0.9290855553637751, 'colsample_bytree': 0.8897266267034629}.\n",
            "[I 2025-02-08 19:59:04,044] Trial 19 finished with values: [0.09367012510759065, 0.5604096562715855] and parameters: {'max_depth': 5, 'learning_rate': 0.11557227048625641, 'n_estimators': 100, 'subsample': 0.6436759765069076, 'colsample_bytree': 0.6241535290607776}.\n",
            "[I 2025-02-08 19:59:47,177] Trial 20 finished with values: [0.09397578686300773, 0.5636030852002344] and parameters: {'max_depth': 7, 'learning_rate': 0.017408640497314807, 'n_estimators': 600, 'subsample': 0.5118588838796492, 'colsample_bytree': 0.5928289039576766}.\n",
            "[I 2025-02-08 20:00:20,159] Trial 21 finished with values: [0.08539431989321673, 0.5438610266466175] and parameters: {'max_depth': 9, 'learning_rate': 0.2537745727222075, 'n_estimators': 350, 'subsample': 0.5568527042972935, 'colsample_bytree': 0.6761548741212073}.\n",
            "[I 2025-02-08 20:00:34,615] Trial 22 finished with values: [0.0883679085267682, 0.5543377540352906] and parameters: {'max_depth': 6, 'learning_rate': 0.1980017023967879, 'n_estimators': 200, 'subsample': 0.5148338200856342, 'colsample_bytree': 0.7074643029062538}.\n",
            "[I 2025-02-08 20:01:04,342] Trial 23 finished with values: [0.09371890693926821, 0.5602989795334844] and parameters: {'max_depth': 4, 'learning_rate': 0.04471512298002756, 'n_estimators': 650, 'subsample': 0.8536286107170243, 'colsample_bytree': 0.5484163951264711}.\n",
            "[I 2025-02-08 20:01:26,986] Trial 24 finished with values: [0.09040785851512399, 0.5592401876214007] and parameters: {'max_depth': 5, 'learning_rate': 0.16012472281379844, 'n_estimators': 400, 'subsample': 0.8620102075749829, 'colsample_bytree': 0.9369994399982795}.\n",
            "[I 2025-02-08 20:01:44,054] Trial 25 finished with values: [0.0874030147721026, 0.5479680376733608] and parameters: {'max_depth': 10, 'learning_rate': 0.1874975935601643, 'n_estimators': 150, 'subsample': 0.666714518398551, 'colsample_bytree': 0.6757225454513663}.\n",
            "[I 2025-02-08 20:02:15,021] Trial 26 finished with values: [0.09340575741687109, 0.5574145842981385] and parameters: {'max_depth': 3, 'learning_rate': 0.019171359779287165, 'n_estimators': 800, 'subsample': 0.7546423715025028, 'colsample_bytree': 0.564144047353743}.\n",
            "[I 2025-02-08 20:02:46,459] Trial 27 finished with values: [0.0943080632684739, 0.5611677674454599] and parameters: {'max_depth': 5, 'learning_rate': 0.019834390641855357, 'n_estimators': 600, 'subsample': 0.8504302545846172, 'colsample_bytree': 0.7590888315625446}.\n",
            "[I 2025-02-08 20:03:39,631] Trial 28 finished with values: [0.09414609120975752, 0.5623468893853413] and parameters: {'max_depth': 6, 'learning_rate': 0.01539114526238896, 'n_estimators': 850, 'subsample': 0.7032530341781187, 'colsample_bytree': 0.7529279915688785}.\n",
            "[I 2025-02-08 20:03:55,734] Trial 29 finished with values: [0.09282468415499352, 0.5570858272336648] and parameters: {'max_depth': 3, 'learning_rate': 0.04207038004967947, 'n_estimators': 400, 'subsample': 0.9808077558698151, 'colsample_bytree': 0.6625599894005596}.\n",
            "[I 2025-02-08 20:04:57,629] Trial 30 finished with values: [0.08542083444164701, 0.5465141205270733] and parameters: {'max_depth': 7, 'learning_rate': 0.26924166709377106, 'n_estimators': 900, 'subsample': 0.8697613207876063, 'colsample_bytree': 0.6369080330960386}.\n",
            "[I 2025-02-08 20:05:34,744] Trial 31 finished with values: [0.09427781806760767, 0.5633388276412237] and parameters: {'max_depth': 7, 'learning_rate': 0.014000188874796059, 'n_estimators': 500, 'subsample': 0.5627069737523698, 'colsample_bytree': 0.7148752255030394}.\n",
            "[I 2025-02-08 20:06:26,465] Trial 32 finished with values: [0.08979880125204219, 0.5553239624597816] and parameters: {'max_depth': 8, 'learning_rate': 0.05067500817774601, 'n_estimators': 650, 'subsample': 0.5013043706824547, 'colsample_bytree': 0.6174756856628748}.\n",
            "[I 2025-02-08 20:07:18,076] Trial 33 finished with values: [0.08660983789939569, 0.5458024423834881] and parameters: {'max_depth': 10, 'learning_rate': 0.10599417527253213, 'n_estimators': 500, 'subsample': 0.5102924560463384, 'colsample_bytree': 0.6511203241382516}.\n",
            "[I 2025-02-08 20:08:08,266] Trial 34 finished with values: [0.09069099175775648, 0.5578610098416785] and parameters: {'max_depth': 7, 'learning_rate': 0.058680924932580654, 'n_estimators': 700, 'subsample': 0.7172055562469913, 'colsample_bytree': 0.5354981423559535}.\n",
            "[I 2025-02-08 20:08:23,323] Trial 35 finished with values: [0.09411374415521706, 0.5604558421883382] and parameters: {'max_depth': 5, 'learning_rate': 0.033518907543534836, 'n_estimators': 250, 'subsample': 0.5627488216826327, 'colsample_bytree': 0.8527870152524362}.\n",
            "[I 2025-02-08 20:09:58,828] Trial 36 finished with values: [0.09249256519754064, 0.5561792706311177] and parameters: {'max_depth': 10, 'learning_rate': 0.01307467916378433, 'n_estimators': 950, 'subsample': 0.9077943558760622, 'colsample_bytree': 0.85411682678854}.\n",
            "[I 2025-02-08 20:10:21,730] Trial 37 finished with values: [0.09489623612296631, 0.562326588644965] and parameters: {'max_depth': 10, 'learning_rate': 0.013654151749655709, 'n_estimators': 200, 'subsample': 0.7074954138953737, 'colsample_bytree': 0.7496051922870699}.\n",
            "[I 2025-02-08 20:11:07,807] Trial 38 finished with values: [0.08548394312022502, 0.5510232934388571] and parameters: {'max_depth': 5, 'learning_rate': 0.2840179539409571, 'n_estimators': 850, 'subsample': 0.6321001648549911, 'colsample_bytree': 0.689011604684475}.\n",
            "[I 2025-02-08 20:12:13,068] Trial 39 finished with values: [0.0848188273313137, 0.5392056334914871] and parameters: {'max_depth': 10, 'learning_rate': 0.261462666858697, 'n_estimators': 600, 'subsample': 0.5550169239463025, 'colsample_bytree': 0.9415523411027874}.\n",
            "[I 2025-02-08 20:12:41,868] Trial 40 finished with values: [0.09430983840889767, 0.563429441794712] and parameters: {'max_depth': 7, 'learning_rate': 0.028626546118150437, 'n_estimators': 400, 'subsample': 0.8267993225376263, 'colsample_bytree': 0.5305267406095173}.\n",
            "[I 2025-02-08 20:13:12,475] Trial 41 finished with values: [0.08980574777540841, 0.5571053299734207] and parameters: {'max_depth': 6, 'learning_rate': 0.14040038536769037, 'n_estimators': 500, 'subsample': 0.8944844121274735, 'colsample_bytree': 0.6253498444672183}.\n",
            "[I 2025-02-08 20:13:20,039] Trial 42 finished with values: [0.0938764881602116, 0.5581105686326876] and parameters: {'max_depth': 4, 'learning_rate': 0.11868348129115208, 'n_estimators': 100, 'subsample': 0.7559194865555001, 'colsample_bytree': 0.677180637059831}.\n",
            "[I 2025-02-08 20:13:52,604] Trial 43 finished with values: [0.09457935126163054, 0.5652212700110606] and parameters: {'max_depth': 8, 'learning_rate': 0.018268029028322433, 'n_estimators': 400, 'subsample': 0.8161493949948719, 'colsample_bytree': 0.575298507723031}.\n",
            "[I 2025-02-08 20:15:11,727] Trial 44 finished with values: [0.0870327653616854, 0.5435216679643556] and parameters: {'max_depth': 10, 'learning_rate': 0.1283492393016913, 'n_estimators': 750, 'subsample': 0.5053275843512683, 'colsample_bytree': 0.8363507406596575}.\n",
            "[I 2025-02-08 20:15:22,889] Trial 45 finished with values: [0.09359328594068739, 0.5585358553774699] and parameters: {'max_depth': 4, 'learning_rate': 0.09290013909221381, 'n_estimators': 200, 'subsample': 0.6652852283018867, 'colsample_bytree': 0.7486275862939188}.\n",
            "[I 2025-02-08 20:16:39,273] Trial 46 finished with values: [0.08540260134213196, 0.5426907209197095] and parameters: {'max_depth': 9, 'learning_rate': 0.1976070291751892, 'n_estimators': 800, 'subsample': 0.5895995274475542, 'colsample_bytree': 0.8389515027027605}.\n",
            "[I 2025-02-08 20:17:08,249] Trial 47 finished with values: [0.09227038977753543, 0.5599553945879489] and parameters: {'max_depth': 7, 'learning_rate': 0.053539771513690694, 'n_estimators': 400, 'subsample': 0.7237760488120395, 'colsample_bytree': 0.5437090972863532}.\n",
            "[I 2025-02-08 20:17:54,790] Trial 48 finished with values: [0.08716222011734355, 0.5531162899908503] and parameters: {'max_depth': 6, 'learning_rate': 0.1797142030319013, 'n_estimators': 750, 'subsample': 0.6615022282753338, 'colsample_bytree': 0.5362554021076629}.\n",
            "[I 2025-02-08 20:19:19,428] Trial 49 finished with values: [0.08715921953840601, 0.5420470159881292] and parameters: {'max_depth': 10, 'learning_rate': 0.16941553627428604, 'n_estimators': 800, 'subsample': 0.9389448244039263, 'colsample_bytree': 0.7329786426973114}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trials:  50\n",
            "Pareto front of best trials:\n",
            "  Values (PR-AUC, BA): [0.09509515162681398, 0.5634506563366933], Params: {'max_depth': 7, 'learning_rate': 0.010292061248376264, 'n_estimators': 450, 'subsample': 0.6929472982028031, 'colsample_bytree': 0.615230123556783}\n",
            "  Values (PR-AUC, BA): [0.09473143451688039, 0.5640053240975528], Params: {'max_depth': 9, 'learning_rate': 0.023925773188120017, 'n_estimators': 150, 'subsample': 0.666692598226888, 'colsample_bytree': 0.5217004195873143}\n",
            "  Values (PR-AUC, BA): [0.09457935126163054, 0.5652212700110606], Params: {'max_depth': 8, 'learning_rate': 0.018268029028322433, 'n_estimators': 400, 'subsample': 0.8161493949948719, 'colsample_bytree': 0.575298507723031}\n",
            "\n",
            "Selected best trial (highest PR-AUC):\n",
            "  Best PR-AUC:  0.09509515162681398\n",
            "  Balanced Accuracy:  0.5634506563366933\n",
            "  Best hyperparameters:  {'max_depth': 7, 'learning_rate': 0.010292061248376264, 'n_estimators': 450, 'subsample': 0.6929472982028031, 'colsample_bytree': 0.615230123556783}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:19:20] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test predictions (first 10): [1 1 0 1 0 0 1 1 1 0]\n",
            "Test predicted probabilities (first 10): [0.50073785 0.686858   0.48863897 0.5365681  0.4802022  0.46566507\n",
            " 0.53684425 0.50450224 0.66169125 0.4196827 ]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Precision (PR-AUC): 0.11090489020791991\n",
            "Validation Balanced Accuracy: 0.6024744055238866\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.model_selection import train_test_split, cross_validate\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score, balanced_accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load the Data\n",
        "# -------------------------------\n",
        "train_path = '/content/train_dataset_full (1).csv'\n",
        "test_path = '/content/X_test_1st.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "test_data = pd.read_csv(test_path)\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Data Cleaning and Feature Extraction\n",
        "# -------------------------------\n",
        "# Drop rows where the target is missing\n",
        "train_data = train_data.dropna(subset=['is_click'])\n",
        "\n",
        "# Convert DateTime columns to datetime objects\n",
        "train_data['DateTime'] = pd.to_datetime(train_data['DateTime'])\n",
        "test_data['DateTime'] = pd.to_datetime(test_data['DateTime'])\n",
        "\n",
        "# Extract date/time features: hour and day of week\n",
        "for df in [train_data, test_data]:\n",
        "    df['hour'] = df['DateTime'].dt.hour\n",
        "    df['dayofweek'] = df['DateTime'].dt.dayofweek\n",
        "\n",
        "# Drop identifier and raw DateTime columns\n",
        "cols_to_drop = ['session_id', 'DateTime', 'user_id'] #avoide leakage\n",
        "train_data.drop(columns=cols_to_drop, inplace=True)\n",
        "test_data.drop(columns=cols_to_drop, inplace=True)\n",
        "\n",
        "# Drop columns with very high missingness (e.g., product_category_2)\n",
        "if 'product_category_2' in train_data.columns:\n",
        "    train_data.drop(columns=['product_category_2'], inplace=True)\n",
        "if 'product_category_2' in test_data.columns:\n",
        "    test_data.drop(columns=['product_category_2'], inplace=True)\n",
        "\n",
        "# Split features and target in the training data\n",
        "X = train_data.drop('is_click', axis=1)\n",
        "y = train_data['is_click']\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Define the Preprocessing Pipeline\n",
        "# -------------------------------\n",
        "# Specify which features are numeric and which are categorical\n",
        "numeric_features = ['campaign_id', 'webpage_id', 'product_category_1', 'age_level',\n",
        "                    'user_depth', 'city_development_index', 'var_1', 'hour', 'dayofweek']\n",
        "categorical_features = ['product', 'gender']\n",
        "\n",
        "# Pipeline for numeric features: impute missing values then scale\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Pipeline for categorical features: impute missing values then one-hot encode\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine transformations with ColumnTransformer\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numeric_transformer, numeric_features),\n",
        "    ('cat', categorical_transformer, categorical_features)\n",
        "])\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Split Data for Hyperparameter Tuning\n",
        "# -------------------------------\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, random_state=42)\n",
        "\n",
        "# Calculate the imbalance ratio for the positive class (used in XGBoost)\n",
        "imbalance_ratio = np.sum(y_train == 0) / np.sum(y_train == 1)\n",
        "print(\"Imbalance Ratio:\", imbalance_ratio)\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Multi-Objective Hyperparameter Optimization with Optuna\n",
        "# -------------------------------\n",
        "def objective(trial):\n",
        "    # Suggest hyperparameters for the XGBClassifier\n",
        "    param = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=50),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'scale_pos_weight': imbalance_ratio,  # adjust for class imbalance\n",
        "        'random_state': 42,\n",
        "        'use_label_encoder': False,\n",
        "        'eval_metric': 'logloss'\n",
        "    }\n",
        "\n",
        "    # Create a pipeline with the preprocessor and XGBoost classifier\n",
        "    clf = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', XGBClassifier(**param))\n",
        "    ])\n",
        "\n",
        "    # Use cross-validation to compute both average precision (PR-AUC) and balanced accuracy.\n",
        "    # We use 3-fold CV here.\n",
        "    scoring = {'ap': 'average_precision', 'ba': 'balanced_accuracy'}\n",
        "    cv_results = cross_validate(clf, X_train, y_train, scoring=scoring, cv=3, n_jobs=-1, error_score=0.0)\n",
        "\n",
        "    mean_ap = np.mean(cv_results['test_ap'])\n",
        "    mean_ba = np.mean(cv_results['test_ba'])\n",
        "\n",
        "    # Since we want to maximize both metrics, we return them as a tuple.\n",
        "    return mean_ap, mean_ba\n",
        "\n",
        "# Create a multi-objective study (maximize both PR-AUC and Balanced Accuracy)\n",
        "study = optuna.create_study(directions=[\"maximize\", \"maximize\"])\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print(\"Number of trials: \", len(study.trials))\n",
        "print(\"Pareto front of best trials:\")\n",
        "for t in study.best_trials:\n",
        "    print(f\"  Values (PR-AUC, BA): {t.values}, Params: {t.params}\")\n",
        "\n",
        "# For this example, we select one candidate from the Pareto front.\n",
        "# Here, we choose the trial with the highest average precision (first objective).\n",
        "best_trial = max(study.best_trials, key=lambda t: t.values[0])\n",
        "print(\"\\nSelected best trial (highest PR-AUC):\")\n",
        "print(\"  Best PR-AUC: \", best_trial.values[0])\n",
        "print(\"  Balanced Accuracy: \", best_trial.values[1])\n",
        "print(\"  Best hyperparameters: \", best_trial.params)\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Train the Final Model on the Full Training Data\n",
        "# -------------------------------\n",
        "# Incorporate the best parameters (and ensure fixed parameters are set)\n",
        "best_params = best_trial.params.copy()\n",
        "best_params.update({\n",
        "    'scale_pos_weight': imbalance_ratio,\n",
        "    'random_state': 42,\n",
        "    'use_label_encoder': False,\n",
        "    'eval_metric': 'logloss'\n",
        "})\n",
        "\n",
        "final_model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', XGBClassifier(**best_params))\n",
        "])\n",
        "\n",
        "# Train the final model using the full training data\n",
        "final_model.fit(X, y)\n",
        "\n",
        "# -------------------------------\n",
        "# 7. Generate Predictions on the Test Data\n",
        "# -------------------------------\n",
        "test_predictions = final_model.predict(test_data)\n",
        "test_probabilities = final_model.predict_proba(test_data)[:, 1]\n",
        "\n",
        "print(\"Test predictions (first 10):\", test_predictions[:10])\n",
        "print(\"Test predicted probabilities (first 10):\", test_probabilities[:10])\n",
        "\n",
        "# -------------------------------\n",
        "# 8. (Optional) Evaluate on Validation Set: Plot Precision-Recall Curve and Compute Metrics\n",
        "# -------------------------------\n",
        "y_val_proba = final_model.predict_proba(X_val)[:, 1]\n",
        "precision, recall, _ = precision_recall_curve(y_val, y_val_proba)\n",
        "ap_score = average_precision_score(y_val, y_val_proba)\n",
        "\n",
        "# Also compute balanced accuracy on the validation set\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "y_val_pred = final_model.predict(X_val)\n",
        "ba_score = balanced_accuracy_score(y_val, y_val_pred)\n",
        "\n",
        "plt.plot(recall, precision, label=f'AP = {ap_score:.2f}')\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"Validation Average Precision (PR-AUC):\", ap_score)\n",
        "print(\"Validation Balanced Accuracy:\", ba_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.model_selection import train_test_split, cross_validate\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score, balanced_accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load the Data\n",
        "# -------------------------------\n",
        "train_path = '/content/train_dataset_full (1).csv'\n",
        "test_path = '/content/X_test_1st.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "test_data = pd.read_csv(test_path)\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Data Cleaning and Feature Extraction\n",
        "# -------------------------------\n",
        "# Drop rows where the target is missing\n",
        "train_data = train_data.dropna(subset=['is_click'])\n",
        "\n",
        "# Convert DateTime columns to datetime objects\n",
        "train_data['DateTime'] = pd.to_datetime(train_data['DateTime'])\n",
        "test_data['DateTime'] = pd.to_datetime(test_data['DateTime'])\n",
        "\n",
        "# Extract date/time features: hour and day of week\n",
        "for df in [train_data, test_data]:\n",
        "    df['hour'] = df['DateTime'].dt.hour\n",
        "    df['dayofweek'] = df['DateTime'].dt.dayofweek\n",
        "\n",
        "# Drop identifier and raw DateTime columns\n",
        "cols_to_drop = ['session_id', 'DateTime', 'user_id','var_1'] #avoide leakage , #var_1?\n",
        "train_data.drop(columns=cols_to_drop, inplace=True)\n",
        "test_data.drop(columns=cols_to_drop, inplace=True)\n",
        "\n",
        "# Drop columns with very high missingness (e.g., product_category_2)\n",
        "if 'product_category_2' in train_data.columns:\n",
        "    train_data.drop(columns=['product_category_2'], inplace=True)\n",
        "if 'product_category_2' in test_data.columns:\n",
        "    test_data.drop(columns=['product_category_2'], inplace=True)\n",
        "\n",
        "# Split features and target in the training data\n",
        "X = train_data.drop('is_click', axis=1)\n",
        "y = train_data['is_click']\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Define the Preprocessing Pipeline\n",
        "# -------------------------------\n",
        "# Specify which features are numeric and which are categorical\n",
        "numeric_features = ['campaign_id', 'webpage_id', 'product_category_1', 'age_level',\n",
        "                    'city_development_index', 'hour', 'dayofweek']\n",
        "categorical_features = ['product', 'gender']\n",
        "\n",
        "# Pipeline for numeric features: impute missing values then scale\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Pipeline for categorical features: impute missing values then one-hot encode\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine transformations with ColumnTransformer\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numeric_transformer, numeric_features),\n",
        "    ('cat', categorical_transformer, categorical_features)\n",
        "])\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Split Data for Hyperparameter Tuning\n",
        "# -------------------------------\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, random_state=42)\n",
        "\n",
        "# Calculate the imbalance ratio for the positive class (used in XGBoost)\n",
        "imbalance_ratio = np.sum(y_train == 0) / np.sum(y_train == 1)\n",
        "print(\"Imbalance Ratio:\", imbalance_ratio)\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Multi-Objective Hyperparameter Optimization with Optuna\n",
        "# -------------------------------\n",
        "def objective(trial):\n",
        "    # Suggest hyperparameters for the XGBClassifier\n",
        "    param = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=50),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'scale_pos_weight': imbalance_ratio,  # adjust for class imbalance\n",
        "        'random_state': 42,\n",
        "        'use_label_encoder': False,\n",
        "        'eval_metric': 'logloss'\n",
        "    }\n",
        "\n",
        "    # Create a pipeline with the preprocessor and XGBoost classifier\n",
        "    clf = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', XGBClassifier(**param))\n",
        "    ])\n",
        "\n",
        "    # Use cross-validation to compute both average precision (PR-AUC) and balanced accuracy.\n",
        "    # We use 3-fold CV here.\n",
        "    scoring = {'ap': 'average_precision', 'ba': 'balanced_accuracy'}\n",
        "    cv_results = cross_validate(clf, X_train, y_train, scoring=scoring, cv=3, n_jobs=-1, error_score=0.0)\n",
        "\n",
        "    mean_ap = np.mean(cv_results['test_ap'])\n",
        "    mean_ba = np.mean(cv_results['test_ba'])\n",
        "\n",
        "    # Since we want to maximize both metrics, we return them as a tuple.\n",
        "    return mean_ap, mean_ba\n",
        "\n",
        "# Create a multi-objective study (maximize both PR-AUC and Balanced Accuracy)\n",
        "study = optuna.create_study(directions=[\"maximize\", \"maximize\"])\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print(\"Number of trials: \", len(study.trials))\n",
        "print(\"Pareto front of best trials:\")\n",
        "for t in study.best_trials:\n",
        "    print(f\"  Values (PR-AUC, BA): {t.values}, Params: {t.params}\")\n",
        "\n",
        "# For this example, we select one candidate from the Pareto front.\n",
        "# Here, we choose the trial with the highest average precision (first objective).\n",
        "best_trial = max(study.best_trials, key=lambda t: t.values[0])\n",
        "print(\"\\nSelected best trial (highest PR-AUC):\")\n",
        "print(\"  Best PR-AUC: \", best_trial.values[0])\n",
        "print(\"  Balanced Accuracy: \", best_trial.values[1])\n",
        "print(\"  Best hyperparameters: \", best_trial.params)\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Train the Final Model on the Full Training Data\n",
        "# -------------------------------\n",
        "# Incorporate the best parameters (and ensure fixed parameters are set)\n",
        "best_params = best_trial.params.copy()\n",
        "best_params.update({\n",
        "    'scale_pos_weight': imbalance_ratio,\n",
        "    'random_state': 42,\n",
        "    'use_label_encoder': False,\n",
        "    'eval_metric': 'logloss'\n",
        "})\n",
        "\n",
        "final_model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', XGBClassifier(**best_params))\n",
        "])\n",
        "\n",
        "# Train the final model using the full training data\n",
        "final_model.fit(X, y)\n",
        "\n",
        "# -------------------------------\n",
        "# 7. Generate Predictions on the Test Data\n",
        "# -------------------------------\n",
        "test_predictions = final_model.predict(test_data)\n",
        "test_probabilities = final_model.predict_proba(test_data)[:, 1]\n",
        "\n",
        "print(\"Test predictions (first 10):\", test_predictions[:10])\n",
        "print(\"Test predicted probabilities (first 10):\", test_probabilities[:10])\n",
        "\n",
        "# -------------------------------\n",
        "# 8. (Optional) Evaluate on Validation Set: Plot Precision-Recall Curve and Compute Metrics\n",
        "# -------------------------------\n",
        "y_val_proba = final_model.predict_proba(X_val)[:, 1]\n",
        "precision, recall, _ = precision_recall_curve(y_val, y_val_proba)\n",
        "ap_score = average_precision_score(y_val, y_val_proba)\n",
        "\n",
        "# Also compute balanced accuracy on the validation set\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "y_val_pred = final_model.predict(X_val)\n",
        "ba_score = balanced_accuracy_score(y_val, y_val_pred)\n",
        "\n",
        "plt.plot(recall, precision, label=f'AP = {ap_score:.2f}')\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"Validation Average Precision (PR-AUC):\", ap_score)\n",
        "print(\"Validation Balanced Accuracy:\", ba_score)\n"
      ],
      "metadata": {
        "id": "mXSOV3MuIvKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.model_selection import train_test_split, cross_validate\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score, balanced_accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load the Data\n",
        "# -------------------------------\n",
        "train_path = '/content/train_dataset_full (1).csv'\n",
        "test_path = '/content/X_test_1st.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "test_data = pd.read_csv(test_path)\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Data Cleaning and Feature Extraction\n",
        "# -------------------------------\n",
        "# Drop rows where the target is missing\n",
        "train_data = train_data.dropna(subset=['is_click'])\n",
        "\n",
        "# Convert DateTime columns to datetime objects\n",
        "train_data['DateTime'] = pd.to_datetime(train_data['DateTime'])\n",
        "test_data['DateTime'] = pd.to_datetime(test_data['DateTime'])\n",
        "\n",
        "# Extract date/time features: hour and day of week\n",
        "for df in [train_data, test_data]:\n",
        "    df['hour'] = df['DateTime'].dt.hour\n",
        "    df['dayofweek'] = df['DateTime'].dt.dayofweek\n",
        "\n",
        "# Drop identifier and raw DateTime columns\n",
        "cols_to_drop = ['session_id', 'DateTime', 'user_id','product_category_2','user_depth'] #avoide leakage , #var_1?\n",
        "train_data.drop(columns=cols_to_drop, inplace=True)\n",
        "test_data.drop(columns=cols_to_drop, inplace=True)\n",
        "\n",
        "# Drop columns with very high missingness (e.g., product_category_2)\n",
        "if 'product_category_2' in train_data.columns:\n",
        "    train_data.drop(columns=['product_category_2'], inplace=True)\n",
        "if 'product_category_2' in test_data.columns:\n",
        "    test_data.drop(columns=['product_category_2'], inplace=True)\n",
        "\n",
        "# Split features and target in the training data\n",
        "X = train_data.drop('is_click', axis=1)\n",
        "y = train_data['is_click']\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Define the Preprocessing Pipeline\n",
        "# -------------------------------\n",
        "# Specify which features are numeric and which are categorical\n",
        "numeric_features = ['campaign_id', 'webpage_id', 'product_category_1', 'age_level',\n",
        "                    'city_development_index', 'var_1', 'hour', 'dayofweek']\n",
        "categorical_features = ['product', 'gender']\n",
        "\n",
        "# Pipeline for numeric features: impute missing values then scale\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Pipeline for categorical features: impute missing values then one-hot encode\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine transformations with ColumnTransformer\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numeric_transformer, numeric_features),\n",
        "    ('cat', categorical_transformer, categorical_features)\n",
        "])\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Split Data for Hyperparameter Tuning\n",
        "# -------------------------------\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, random_state=42)\n",
        "\n",
        "# Calculate the imbalance ratio for the positive class (used in XGBoost)\n",
        "imbalance_ratio = np.sum(y_train == 0) / np.sum(y_train == 1)\n",
        "print(\"Imbalance Ratio:\", imbalance_ratio)\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Multi-Objective Hyperparameter Optimization with Optuna\n",
        "# -------------------------------\n",
        "def objective(trial):\n",
        "    # Suggest hyperparameters for the XGBClassifier\n",
        "    param = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=50),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'scale_pos_weight': imbalance_ratio,  # adjust for class imbalance\n",
        "        'random_state': 42,\n",
        "        'use_label_encoder': False,\n",
        "        'eval_metric': 'logloss'\n",
        "    }\n",
        "\n",
        "    # Create a pipeline with the preprocessor and XGBoost classifier\n",
        "    clf = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', XGBClassifier(**param))\n",
        "    ])\n",
        "\n",
        "    # Use cross-validation to compute both average precision (PR-AUC) and balanced accuracy.\n",
        "    # We use 3-fold CV here.\n",
        "    scoring = {'ap': 'average_precision', 'ba': 'balanced_accuracy'}\n",
        "    cv_results = cross_validate(clf, X_train, y_train, scoring=scoring, cv=3, n_jobs=-1, error_score=0.0)\n",
        "\n",
        "    mean_ap = np.mean(cv_results['test_ap'])\n",
        "    mean_ba = np.mean(cv_results['test_ba'])\n",
        "\n",
        "    # Since we want to maximize both metrics, we return them as a tuple.\n",
        "    return mean_ap, mean_ba\n",
        "\n",
        "# Create a multi-objective study (maximize both PR-AUC and Balanced Accuracy)\n",
        "study = optuna.create_study(directions=[\"maximize\", \"maximize\"])\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print(\"Number of trials: \", len(study.trials))\n",
        "print(\"Pareto front of best trials:\")\n",
        "for t in study.best_trials:\n",
        "    print(f\"  Values (PR-AUC, BA): {t.values}, Params: {t.params}\")\n",
        "\n",
        "# For this example, we select one candidate from the Pareto front.\n",
        "# Here, we choose the trial with the highest average precision (first objective).\n",
        "best_trial = max(study.best_trials, key=lambda t: t.values[0])\n",
        "print(\"\\nSelected best trial (highest PR-AUC):\")\n",
        "print(\"  Best PR-AUC: \", best_trial.values[0])\n",
        "print(\"  Balanced Accuracy: \", best_trial.values[1])\n",
        "print(\"  Best hyperparameters: \", best_trial.params)\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Train the Final Model on the Full Training Data\n",
        "# -------------------------------\n",
        "# Incorporate the best parameters (and ensure fixed parameters are set)\n",
        "best_params = best_trial.params.copy()\n",
        "best_params.update({\n",
        "    'scale_pos_weight': imbalance_ratio,\n",
        "    'random_state': 42,\n",
        "    'use_label_encoder': False,\n",
        "    'eval_metric': 'logloss'\n",
        "})\n",
        "\n",
        "final_model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', XGBClassifier(**best_params))\n",
        "])\n",
        "\n",
        "# Train the final model using the full training data\n",
        "final_model.fit(X, y)\n",
        "\n",
        "# -------------------------------\n",
        "# 7. Generate Predictions on the Test Data\n",
        "# -------------------------------\n",
        "test_predictions = final_model.predict(test_data)\n",
        "test_probabilities = final_model.predict_proba(test_data)[:, 1]\n",
        "\n",
        "print(\"Test predictions (first 10):\", test_predictions[:10])\n",
        "print(\"Test predicted probabilities (first 10):\", test_probabilities[:10])\n",
        "\n",
        "# -------------------------------\n",
        "# 8. (Optional) Evaluate on Validation Set: Plot Precision-Recall Curve and Compute Metrics\n",
        "# -------------------------------\n",
        "y_val_proba = final_model.predict_proba(X_val)[:, 1]\n",
        "precision, recall, _ = precision_recall_curve(y_val, y_val_proba)\n",
        "ap_score = average_precision_score(y_val, y_val_proba)\n",
        "\n",
        "# Also compute balanced accuracy on the validation set\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "y_val_pred = final_model.predict(X_val)\n",
        "ba_score = balanced_accuracy_score(y_val, y_val_pred)\n",
        "\n",
        "plt.plot(recall, precision, label=f'AP = {ap_score:.2f}')\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"Validation Average Precision (PR-AUC):\", ap_score)\n",
        "print(\"Validation Balanced Accuracy:\", ba_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DWaozPkh923y",
        "outputId": "57e65111-d01d-4607-b500-66918d80b8ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-08 20:19:43,668] A new study created in memory with name: no-name-580e9147-17b3-4b38-a82a-4805348080fa\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imbalance Ratio: 13.79824741211438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-08 20:20:25,022] Trial 0 finished with values: [0.09387790234252003, 0.5602906005190675] and parameters: {'max_depth': 4, 'learning_rate': 0.033338547791937775, 'n_estimators': 550, 'subsample': 0.9593972342214738, 'colsample_bytree': 0.9253906289537204}.\n",
            "[I 2025-02-08 20:20:37,207] Trial 1 finished with values: [0.09360971260681832, 0.5599930773442406] and parameters: {'max_depth': 3, 'learning_rate': 0.10210451354207888, 'n_estimators': 250, 'subsample': 0.6556232477014294, 'colsample_bytree': 0.8655953789405182}.\n",
            "[I 2025-02-08 20:22:13,836] Trial 2 finished with values: [0.08855449785623974, 0.5488317121746303] and parameters: {'max_depth': 10, 'learning_rate': 0.03876632986729577, 'n_estimators': 950, 'subsample': 0.9450718489702798, 'colsample_bytree': 0.7757440246376462}.\n",
            "[I 2025-02-08 20:23:37,872] Trial 3 finished with values: [0.08976670003725196, 0.5517546998227092] and parameters: {'max_depth': 9, 'learning_rate': 0.024239382974166095, 'n_estimators': 950, 'subsample': 0.8447571848956461, 'colsample_bytree': 0.9035761335500816}.\n",
            "[I 2025-02-08 20:24:15,722] Trial 4 finished with values: [0.08426045562098239, 0.5485530089730316] and parameters: {'max_depth': 7, 'learning_rate': 0.29555219973474933, 'n_estimators': 550, 'subsample': 0.781955158629698, 'colsample_bytree': 0.5549955891480953}.\n",
            "[I 2025-02-08 20:24:47,515] Trial 5 finished with values: [0.09326994997298764, 0.558029232877672] and parameters: {'max_depth': 3, 'learning_rate': 0.022703243077001514, 'n_estimators': 850, 'subsample': 0.9750911475065549, 'colsample_bytree': 0.5658361102819291}.\n",
            "[I 2025-02-08 20:25:18,325] Trial 6 finished with values: [0.09468280562135067, 0.5642627078914515] and parameters: {'max_depth': 6, 'learning_rate': 0.020688546995682944, 'n_estimators': 500, 'subsample': 0.843886214868102, 'colsample_bytree': 0.6856264662593194}.\n",
            "[I 2025-02-08 20:25:54,568] Trial 7 finished with values: [0.09415570280505102, 0.5600527627184947] and parameters: {'max_depth': 4, 'learning_rate': 0.011939047837726547, 'n_estimators': 800, 'subsample': 0.5343269462968654, 'colsample_bytree': 0.7808468277718056}.\n",
            "[I 2025-02-08 20:26:26,659] Trial 8 finished with values: [0.08921112416723877, 0.5519252517056513] and parameters: {'max_depth': 10, 'learning_rate': 0.0491160487508221, 'n_estimators': 300, 'subsample': 0.559817078243821, 'colsample_bytree': 0.9202391454649135}.\n",
            "[I 2025-02-08 20:27:19,496] Trial 9 finished with values: [0.09234220329658077, 0.5591512428288082] and parameters: {'max_depth': 9, 'learning_rate': 0.021225978962030493, 'n_estimators': 600, 'subsample': 0.79842724236304, 'colsample_bytree': 0.7365763712234594}.\n",
            "[I 2025-02-08 20:28:05,088] Trial 10 finished with values: [0.08857054903036234, 0.5498635018523064] and parameters: {'max_depth': 9, 'learning_rate': 0.05809968027175939, 'n_estimators': 500, 'subsample': 0.6854316160404235, 'colsample_bytree': 0.8531453042114536}.\n",
            "[I 2025-02-08 20:28:16,194] Trial 11 finished with values: [0.0914020561523291, 0.556338757645371] and parameters: {'max_depth': 9, 'learning_rate': 0.11457553896557333, 'n_estimators': 100, 'subsample': 0.9021026098272087, 'colsample_bytree': 0.9793018163811326}.\n",
            "[I 2025-02-08 20:29:12,468] Trial 12 finished with values: [0.08593315003482761, 0.5466996510847545] and parameters: {'max_depth': 8, 'learning_rate': 0.18111217527027038, 'n_estimators': 700, 'subsample': 0.8781800440655235, 'colsample_bytree': 0.6027601980183918}.\n",
            "[I 2025-02-08 20:29:43,155] Trial 13 finished with values: [0.09079766601873884, 0.5523632764566764] and parameters: {'max_depth': 10, 'learning_rate': 0.04725677549031614, 'n_estimators': 300, 'subsample': 0.8969185703506304, 'colsample_bytree': 0.9344011053937649}.\n",
            "[I 2025-02-08 20:30:35,645] Trial 14 finished with values: [0.08691156997996008, 0.5538031797580129] and parameters: {'max_depth': 6, 'learning_rate': 0.1309519440034873, 'n_estimators': 850, 'subsample': 0.5945190786257558, 'colsample_bytree': 0.7450757857174024}.\n",
            "[I 2025-02-08 20:31:20,279] Trial 15 finished with values: [0.09398776187283475, 0.560340593271508] and parameters: {'max_depth': 4, 'learning_rate': 0.018156234374427888, 'n_estimators': 1000, 'subsample': 0.5934599859055989, 'colsample_bytree': 0.6933498189146615}.\n",
            "[I 2025-02-08 20:31:33,926] Trial 16 finished with values: [0.09173056251241611, 0.5596631576627219] and parameters: {'max_depth': 8, 'learning_rate': 0.09277153556058274, 'n_estimators': 150, 'subsample': 0.5886778551367026, 'colsample_bytree': 0.7716832449145643}.\n",
            "[I 2025-02-08 20:31:50,740] Trial 17 finished with values: [0.08752376890872281, 0.5468263405739575] and parameters: {'max_depth': 10, 'learning_rate': 0.1914378700020291, 'n_estimators': 150, 'subsample': 0.9454217631154953, 'colsample_bytree': 0.9826212706307473}.\n",
            "[I 2025-02-08 20:32:38,855] Trial 18 finished with values: [0.08710826292758267, 0.5499246363343785] and parameters: {'max_depth': 7, 'learning_rate': 0.1062350889165964, 'n_estimators': 700, 'subsample': 0.7525067656797653, 'colsample_bytree': 0.8889284194015092}.\n",
            "[I 2025-02-08 20:33:14,640] Trial 19 finished with values: [0.0865918639870531, 0.5472466551985969] and parameters: {'max_depth': 8, 'learning_rate': 0.21800735611527935, 'n_estimators': 450, 'subsample': 0.9817946815464443, 'colsample_bytree': 0.8432974692667659}.\n",
            "[I 2025-02-08 20:33:48,188] Trial 20 finished with values: [0.08448917667411533, 0.5438219601017913] and parameters: {'max_depth': 8, 'learning_rate': 0.25294923502663186, 'n_estimators': 400, 'subsample': 0.6069089837908269, 'colsample_bytree': 0.7817687293482549}.\n",
            "[I 2025-02-08 20:34:56,273] Trial 21 finished with values: [0.08661165773675521, 0.5463811039575329] and parameters: {'max_depth': 9, 'learning_rate': 0.07821848157928175, 'n_estimators': 750, 'subsample': 0.6892415508154865, 'colsample_bytree': 0.7313931227883763}.\n",
            "[I 2025-02-08 20:35:36,166] Trial 22 finished with values: [0.09069918100953948, 0.5597573698545854] and parameters: {'max_depth': 4, 'learning_rate': 0.1570750730254895, 'n_estimators': 900, 'subsample': 0.8663333797329158, 'colsample_bytree': 0.9625363542059275}.\n",
            "[I 2025-02-08 20:36:03,936] Trial 23 finished with values: [0.09356225359338038, 0.5601175523555472] and parameters: {'max_depth': 3, 'learning_rate': 0.04069240148383913, 'n_estimators': 700, 'subsample': 0.5821132501503645, 'colsample_bytree': 0.5179467878189239}.\n",
            "[I 2025-02-08 20:36:22,722] Trial 24 finished with values: [0.09393822318244195, 0.5637548726225703] and parameters: {'max_depth': 6, 'learning_rate': 0.039224597844257615, 'n_estimators': 300, 'subsample': 0.6728741575463139, 'colsample_bytree': 0.881409663564749}.\n",
            "[I 2025-02-08 20:37:11,218] Trial 25 finished with values: [0.08581573636617638, 0.5445990309077783] and parameters: {'max_depth': 10, 'learning_rate': 0.29306119420316135, 'n_estimators': 450, 'subsample': 0.9179787891188126, 'colsample_bytree': 0.7973615397538021}.\n",
            "[I 2025-02-08 20:38:24,774] Trial 26 finished with values: [0.0930383867637601, 0.5600868044769962] and parameters: {'max_depth': 9, 'learning_rate': 0.010141398451151027, 'n_estimators': 850, 'subsample': 0.6703317969917413, 'colsample_bytree': 0.7624573468470255}.\n",
            "[I 2025-02-08 20:38:41,258] Trial 27 finished with values: [0.09190912186362594, 0.5573276440051644] and parameters: {'max_depth': 3, 'learning_rate': 0.29917345644924154, 'n_estimators': 400, 'subsample': 0.7253396384051796, 'colsample_bytree': 0.5056826316169432}.\n",
            "[I 2025-02-08 20:39:05,348] Trial 28 finished with values: [0.09311300391256477, 0.5592202142089243] and parameters: {'max_depth': 3, 'learning_rate': 0.09532322661292511, 'n_estimators': 600, 'subsample': 0.7413490027035116, 'colsample_bytree': 0.7074150408163733}.\n",
            "[I 2025-02-08 20:39:55,406] Trial 29 finished with values: [0.09311676907806103, 0.5587455734080737] and parameters: {'max_depth': 10, 'learning_rate': 0.012586915991430227, 'n_estimators': 500, 'subsample': 0.7114912634970556, 'colsample_bytree': 0.8833645219206601}.\n",
            "[I 2025-02-08 20:40:51,047] Trial 30 finished with values: [0.08520401927320803, 0.5437900794783861] and parameters: {'max_depth': 9, 'learning_rate': 0.14501632882946622, 'n_estimators': 600, 'subsample': 0.5539195679614732, 'colsample_bytree': 0.9601412742730595}.\n",
            "[I 2025-02-08 20:41:25,903] Trial 31 finished with values: [0.09198401972131248, 0.5609029596626846] and parameters: {'max_depth': 3, 'learning_rate': 0.23150313667149486, 'n_estimators': 950, 'subsample': 0.984593439674262, 'colsample_bytree': 0.6128842497404365}.\n",
            "[I 2025-02-08 20:41:37,719] Trial 32 finished with values: [0.0929411688709309, 0.5587305182753518] and parameters: {'max_depth': 10, 'learning_rate': 0.04155765648529311, 'n_estimators': 100, 'subsample': 0.6092870893175458, 'colsample_bytree': 0.8258829913983812}.\n",
            "[I 2025-02-08 20:42:53,445] Trial 33 finished with values: [0.08867411367075621, 0.548426303828168] and parameters: {'max_depth': 10, 'learning_rate': 0.03810759957850862, 'n_estimators': 750, 'subsample': 0.8607139090140373, 'colsample_bytree': 0.9451431355288535}.\n",
            "[I 2025-02-08 20:43:03,522] Trial 34 finished with values: [0.09519244501486328, 0.5633353740815402] and parameters: {'max_depth': 7, 'learning_rate': 0.013397017049267084, 'n_estimators': 100, 'subsample': 0.9526557802666198, 'colsample_bytree': 0.8819621778663163}.\n",
            "[I 2025-02-08 20:44:17,453] Trial 35 finished with values: [0.08657806878724132, 0.5485818646800578] and parameters: {'max_depth': 9, 'learning_rate': 0.0806233016277269, 'n_estimators': 800, 'subsample': 0.7422914727381644, 'colsample_bytree': 0.5776971877382076}.\n",
            "[I 2025-02-08 20:44:23,508] Trial 36 finished with values: [0.09198388149552068, 0.5549153151572414] and parameters: {'max_depth': 3, 'learning_rate': 0.022326867470181113, 'n_estimators': 100, 'subsample': 0.7822604196879586, 'colsample_bytree': 0.5106239071985155}.\n",
            "[I 2025-02-08 20:44:56,474] Trial 37 finished with values: [0.09344845815868595, 0.5606751066156992] and parameters: {'max_depth': 4, 'learning_rate': 0.04316434829589462, 'n_estimators': 700, 'subsample': 0.5953943212215062, 'colsample_bytree': 0.6256521191297089}.\n",
            "[I 2025-02-08 20:45:13,342] Trial 38 finished with values: [0.09342391144761268, 0.5595986797116463] and parameters: {'max_depth': 3, 'learning_rate': 0.10854803726612362, 'n_estimators': 450, 'subsample': 0.9867256146331913, 'colsample_bytree': 0.8116922838183678}.\n",
            "[I 2025-02-08 20:45:25,051] Trial 39 finished with values: [0.09514492382869312, 0.5641047921784097] and parameters: {'max_depth': 9, 'learning_rate': 0.015329448050716104, 'n_estimators': 100, 'subsample': 0.676850957634459, 'colsample_bytree': 0.5113106060203472}.\n",
            "[I 2025-02-08 20:46:06,125] Trial 40 finished with values: [0.09370970610578556, 0.560236656131056] and parameters: {'max_depth': 4, 'learning_rate': 0.021039624538913282, 'n_estimators': 900, 'subsample': 0.5807406074839017, 'colsample_bytree': 0.9349462421470198}.\n",
            "[I 2025-02-08 20:46:23,940] Trial 41 finished with values: [0.09392398961272182, 0.5605636144298324] and parameters: {'max_depth': 4, 'learning_rate': 0.03105320045040567, 'n_estimators': 400, 'subsample': 0.9408839339525525, 'colsample_bytree': 0.9789567799497815}.\n",
            "[I 2025-02-08 20:47:01,672] Trial 42 finished with values: [0.08583297139402495, 0.5431463777484526] and parameters: {'max_depth': 10, 'learning_rate': 0.2782729764543007, 'n_estimators': 350, 'subsample': 0.8916073037489258, 'colsample_bytree': 0.9562205633589556}.\n",
            "[I 2025-02-08 20:47:51,710] Trial 43 finished with values: [0.08684665019133775, 0.5505505135686547] and parameters: {'max_depth': 9, 'learning_rate': 0.10131658980927152, 'n_estimators': 550, 'subsample': 0.7576809004758528, 'colsample_bytree': 0.5429789454668758}.\n",
            "[I 2025-02-08 20:48:49,482] Trial 44 finished with values: [0.08463078844030979, 0.5445233169414115] and parameters: {'max_depth': 7, 'learning_rate': 0.28685463557486285, 'n_estimators': 850, 'subsample': 0.950530490306357, 'colsample_bytree': 0.7114925927556497}.\n",
            "[I 2025-02-08 20:49:13,753] Trial 45 finished with values: [0.09407868375014938, 0.5595748790970391] and parameters: {'max_depth': 4, 'learning_rate': 0.019346234751787407, 'n_estimators': 500, 'subsample': 0.6451355860763169, 'colsample_bytree': 0.9621821106726184}.\n",
            "[I 2025-02-08 20:50:06,835] Trial 46 finished with values: [0.09421720916960456, 0.5633327816056206] and parameters: {'max_depth': 6, 'learning_rate': 0.014857729460205837, 'n_estimators': 900, 'subsample': 0.7504899511220631, 'colsample_bytree': 0.8746709086636781}.\n",
            "[I 2025-02-08 20:50:25,057] Trial 47 finished with values: [0.09376178613756747, 0.5579695311305843] and parameters: {'max_depth': 4, 'learning_rate': 0.01621319562350188, 'n_estimators': 400, 'subsample': 0.9914679583141961, 'colsample_bytree': 0.7687674347459985}.\n",
            "[I 2025-02-08 20:51:18,157] Trial 48 finished with values: [0.08427973949704089, 0.5406679850765053] and parameters: {'max_depth': 10, 'learning_rate': 0.20397580254940348, 'n_estimators': 500, 'subsample': 0.5195710595285087, 'colsample_bytree': 0.9539720981753397}.\n",
            "[I 2025-02-08 20:52:32,457] Trial 49 finished with values: [0.08860513173019763, 0.5505411131531853] and parameters: {'max_depth': 8, 'learning_rate': 0.057818801876878816, 'n_estimators': 1000, 'subsample': 0.9577431400542497, 'colsample_bytree': 0.6517857659643945}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trials:  50\n",
            "Pareto front of best trials:\n",
            "  Values (PR-AUC, BA): [0.09468280562135067, 0.5642627078914515], Params: {'max_depth': 6, 'learning_rate': 0.020688546995682944, 'n_estimators': 500, 'subsample': 0.843886214868102, 'colsample_bytree': 0.6856264662593194}\n",
            "  Values (PR-AUC, BA): [0.09519244501486328, 0.5633353740815402], Params: {'max_depth': 7, 'learning_rate': 0.013397017049267084, 'n_estimators': 100, 'subsample': 0.9526557802666198, 'colsample_bytree': 0.8819621778663163}\n",
            "  Values (PR-AUC, BA): [0.09514492382869312, 0.5641047921784097], Params: {'max_depth': 9, 'learning_rate': 0.015329448050716104, 'n_estimators': 100, 'subsample': 0.676850957634459, 'colsample_bytree': 0.5113106060203472}\n",
            "\n",
            "Selected best trial (highest PR-AUC):\n",
            "  Best PR-AUC:  0.09519244501486328\n",
            "  Balanced Accuracy:  0.5633353740815402\n",
            "  Best hyperparameters:  {'max_depth': 7, 'learning_rate': 0.013397017049267084, 'n_estimators': 100, 'subsample': 0.9526557802666198, 'colsample_bytree': 0.8819621778663163}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:52:33] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test predictions (first 10): [0 1 0 1 0 0 1 0 1 0]\n",
            "Test predicted probabilities (first 10): [0.499151   0.6518524  0.4973482  0.53869146 0.49434713 0.47354126\n",
            " 0.5285264  0.49157423 0.6265101  0.44121462]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Precision (PR-AUC): 0.10292706350680811\n",
            "Validation Balanced Accuracy: 0.5783300703143334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "from sklearn.model_selection import train_test_split, cross_validate\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score, balanced_accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load the Data\n",
        "# -------------------------------\n",
        "train_path = '/content/train_dataset_full (1).csv'\n",
        "test_path = '/content/X_test_1st.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "test_data = pd.read_csv(test_path)\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Data Cleaning and Feature Extraction\n",
        "# -------------------------------\n",
        "# Drop rows where the target is missing\n",
        "train_data = train_data.dropna(subset=['is_click'])\n",
        "\n",
        "# Convert DateTime columns to datetime objects\n",
        "train_data['DateTime'] = pd.to_datetime(train_data['DateTime'])\n",
        "test_data['DateTime'] = pd.to_datetime(test_data['DateTime'])\n",
        "\n",
        "# Extract date/time features: hour and day of week\n",
        "for df in [train_data, test_data]:\n",
        "    df['hour'] = df['DateTime'].dt.hour\n",
        "    df['dayofweek'] = df['DateTime'].dt.dayofweek\n",
        "\n",
        "# Drop identifier and raw DateTime columns\n",
        "cols_to_drop = ['session_id', 'DateTime', 'user_id']\n",
        "train_data.drop(columns=cols_to_drop, inplace=True)\n",
        "test_data.drop(columns=cols_to_drop, inplace=True)\n",
        "\n",
        "# Drop columns with very high missingness (e.g., product_category_2)\n",
        "if 'product_category_2' in train_data.columns:\n",
        "    train_data.drop(columns=['product_category_2'], inplace=True)\n",
        "if 'product_category_2' in test_data.columns:\n",
        "    test_data.drop(columns=['product_category_2'], inplace=True)\n",
        "\n",
        "# Split features and target in the training data\n",
        "X = train_data.drop('is_click', axis=1)\n",
        "y = train_data['is_click']\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Define the Preprocessing Pipeline\n",
        "# -------------------------------\n",
        "# Specify which features are numeric and which are categorical\n",
        "numeric_features = ['campaign_id', 'webpage_id', 'product_category_1', 'age_level',\n",
        "                    'user_depth', 'city_development_index', 'var_1', 'hour', 'dayofweek']\n",
        "categorical_features = ['product', 'gender']\n",
        "\n",
        "# Pipeline for numeric features: impute missing values then scale\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Pipeline for categorical features: impute missing values then one-hot encode\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine transformations with ColumnTransformer\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numeric_transformer, numeric_features),\n",
        "    ('cat', categorical_transformer, categorical_features)\n",
        "])\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Split Data for Hyperparameter Tuning\n",
        "# -------------------------------\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, random_state=42)\n",
        "\n",
        "# Calculate the imbalance ratio for the positive class (used in XGBoost)\n",
        "imbalance_ratio = np.sum(y_train == 0) / np.sum(y_train == 1)\n",
        "print(\"Imbalance Ratio:\", imbalance_ratio)\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Multi-Objective Hyperparameter Optimization with Optuna\n",
        "# -------------------------------\n",
        "def objective(trial):\n",
        "    # Suggest hyperparameters for the XGBClassifier\n",
        "    param = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=50),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'scale_pos_weight': imbalance_ratio,  # adjust for class imbalance\n",
        "        'random_state': 42,\n",
        "        'use_label_encoder': False,\n",
        "        'eval_metric': 'logloss'\n",
        "    }\n",
        "\n",
        "    # Create a pipeline with the preprocessor and XGBoost classifier\n",
        "    clf = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', XGBClassifier(**param))\n",
        "    ])\n",
        "\n",
        "    # Use cross-validation to compute both average precision (PR-AUC) and balanced accuracy.\n",
        "    # We use 3-fold CV here.\n",
        "    scoring = {'ap': 'average_precision', 'ba': 'balanced_accuracy'}\n",
        "    cv_results = cross_validate(clf, X_train, y_train, scoring=scoring, cv=3, n_jobs=-1, error_score=0.0)\n",
        "\n",
        "    mean_ap = np.mean(cv_results['test_ap'])\n",
        "    mean_ba = np.mean(cv_results['test_ba'])\n",
        "\n",
        "    # Since we want to maximize both metrics, we return them as a tuple.\n",
        "    return mean_ap, mean_ba\n",
        "\n",
        "# Create a multi-objective study (maximize both PR-AUC and Balanced Accuracy)\n",
        "study = optuna.create_study(directions=[\"maximize\", \"maximize\"])\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print(\"Number of trials: \", len(study.trials))\n",
        "print(\"Pareto front of best trials:\")\n",
        "for t in study.best_trials:\n",
        "    print(f\"  Values (PR-AUC, BA): {t.values}, Params: {t.params}\")\n",
        "\n",
        "# For this example, we select one candidate from the Pareto front.\n",
        "# Here, we choose the trial with the highest average precision (first objective).\n",
        "best_trial = max(study.best_trials, key=lambda t: t.values[0])\n",
        "print(\"\\nSelected best trial (highest PR-AUC):\")\n",
        "print(\"  Best PR-AUC: \", best_trial.values[0])\n",
        "print(\"  Balanced Accuracy: \", best_trial.values[1])\n",
        "print(\"  Best hyperparameters: \", best_trial.params)\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Train the Final Model on the Full Training Data\n",
        "# -------------------------------\n",
        "# Incorporate the best parameters (and ensure fixed parameters are set)\n",
        "best_params = best_trial.params.copy()\n",
        "best_params.update({\n",
        "    'scale_pos_weight': imbalance_ratio,\n",
        "    'random_state': 42,\n",
        "    'use_label_encoder': False,\n",
        "    'eval_metric': 'logloss'\n",
        "})\n",
        "\n",
        "final_model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', XGBClassifier(**best_params))\n",
        "])\n",
        "\n",
        "# Train the final model using the full training data\n",
        "final_model.fit(X, y)\n",
        "\n",
        "# -------------------------------\n",
        "# 7. Generate Predictions on the Test Data\n",
        "# -------------------------------\n",
        "test_predictions = final_model.predict(test_data)\n",
        "test_probabilities = final_model.predict_proba(test_data)[:, 1]\n",
        "\n",
        "print(\"Test predictions (first 10):\", test_predictions[:10])\n",
        "print(\"Test predicted probabilities (first 10):\", test_probabilities[:10])\n",
        "\n",
        "# -------------------------------\n",
        "# 8. (Optional) Evaluate on Validation Set: Plot Precision-Recall Curve and Compute Metrics\n",
        "# -------------------------------\n",
        "y_val_proba = final_model.predict_proba(X_val)[:, 1]\n",
        "precision, recall, _ = precision_recall_curve(y_val, y_val_proba)\n",
        "ap_score = average_precision_score(y_val, y_val_proba)\n",
        "\n",
        "# Also compute balanced accuracy on the validation set\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "y_val_pred = final_model.predict(X_val)\n",
        "ba_score = balanced_accuracy_score(y_val, y_val_pred)\n",
        "\n",
        "plt.plot(recall, precision, label=f'AP = {ap_score:.2f}')\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"Validation Average Precision (PR-AUC):\", ap_score)\n",
        "print(\"Validation Balanced Accuracy:\", ba_score)\n"
      ],
      "metadata": {
        "id": "gSrH0P9BW8W9",
        "outputId": "b06d86a8-6b35-46d8-91d2-ae1ed4517df6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-09 06:19:45,700] A new study created in memory with name: no-name-e5fa95ad-c3f9-44de-a102-329323a8f21f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imbalance Ratio: 13.79824741211438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-09 06:20:30,793] Trial 0 finished with values: [0.08975836042876656, 0.5578324147518915] and parameters: {'max_depth': 4, 'learning_rate': 0.17500996236983038, 'n_estimators': 600, 'subsample': 0.5281482412861275, 'colsample_bytree': 0.9531064810752147}.\n",
            "[I 2025-02-09 06:22:11,040] Trial 1 finished with values: [0.08594821600564927, 0.5440486357519964] and parameters: {'max_depth': 9, 'learning_rate': 0.1461204718144939, 'n_estimators': 1000, 'subsample': 0.6022659375330011, 'colsample_bytree': 0.6903062300838158}.\n",
            "[I 2025-02-09 06:23:48,285] Trial 2 finished with values: [0.08818728761030643, 0.5434271001275786] and parameters: {'max_depth': 10, 'learning_rate': 0.09120528219675508, 'n_estimators': 850, 'subsample': 0.9582285902286511, 'colsample_bytree': 0.9058334431651562}.\n",
            "[I 2025-02-09 06:23:59,480] Trial 3 finished with values: [0.08796787899257497, 0.5538529426565609] and parameters: {'max_depth': 8, 'learning_rate': 0.20420926952838767, 'n_estimators': 100, 'subsample': 0.5567670735625263, 'colsample_bytree': 0.8227212521555047}.\n",
            "[I 2025-02-09 06:24:57,695] Trial 4 finished with values: [0.09181400638268593, 0.5606673040878033] and parameters: {'max_depth': 6, 'learning_rate': 0.04491521304439216, 'n_estimators': 950, 'subsample': 0.9098292471364169, 'colsample_bytree': 0.6955799601022835}.\n",
            "[I 2025-02-09 06:25:33,132] Trial 5 finished with values: [0.08883014568929255, 0.5546791737544198] and parameters: {'max_depth': 5, 'learning_rate': 0.17051005414051362, 'n_estimators': 650, 'subsample': 0.7190745630468152, 'colsample_bytree': 0.7165520073341514}.\n",
            "[I 2025-02-09 06:25:54,722] Trial 6 finished with values: [0.09520251897750738, 0.5627427173702726] and parameters: {'max_depth': 7, 'learning_rate': 0.013300952811159497, 'n_estimators': 250, 'subsample': 0.703613432745979, 'colsample_bytree': 0.6988061156553222}.\n",
            "[I 2025-02-09 06:26:14,339] Trial 7 finished with values: [0.0866149429315405, 0.5477124524009516] and parameters: {'max_depth': 9, 'learning_rate': 0.18431619876607871, 'n_estimators': 200, 'subsample': 0.5558748076672725, 'colsample_bytree': 0.7317360634526897}.\n",
            "[I 2025-02-09 06:26:57,773] Trial 8 finished with values: [0.08439890460961041, 0.5443468686285995] and parameters: {'max_depth': 8, 'learning_rate': 0.29837678572653714, 'n_estimators': 500, 'subsample': 0.6079640959332222, 'colsample_bytree': 0.7686432443008147}.\n",
            "[I 2025-02-09 06:27:07,293] Trial 9 finished with values: [0.09357594727600642, 0.5624566557066397] and parameters: {'max_depth': 6, 'learning_rate': 0.143801081716646, 'n_estimators': 100, 'subsample': 0.953661509768919, 'colsample_bytree': 0.6348681187877747}.\n",
            "[I 2025-02-09 06:27:15,861] Trial 10 finished with values: [0.0949035401094635, 0.5610834851849181] and parameters: {'max_depth': 6, 'learning_rate': 0.03143141756527302, 'n_estimators': 100, 'subsample': 0.9723977014091101, 'colsample_bytree': 0.769350773029702}.\n",
            "[I 2025-02-09 06:27:41,834] Trial 11 finished with values: [0.09011827760454046, 0.5576269327454015] and parameters: {'max_depth': 6, 'learning_rate': 0.10988051670080563, 'n_estimators': 400, 'subsample': 0.6732254222545943, 'colsample_bytree': 0.8825414149589279}.\n",
            "[I 2025-02-09 06:29:27,837] Trial 12 finished with values: [0.0895005250692615, 0.5496206522102517] and parameters: {'max_depth': 10, 'learning_rate': 0.04521911135246153, 'n_estimators': 1000, 'subsample': 0.9555364840742668, 'colsample_bytree': 0.5180315510513752}.\n",
            "[I 2025-02-09 06:30:09,796] Trial 13 finished with values: [0.08807483141226584, 0.5456178187468074] and parameters: {'max_depth': 9, 'learning_rate': 0.10427679835997283, 'n_estimators': 450, 'subsample': 0.8693716719889197, 'colsample_bytree': 0.8437430074080936}.\n",
            "[I 2025-02-09 06:31:09,157] Trial 14 finished with values: [0.09287918175235786, 0.5598854678567556] and parameters: {'max_depth': 10, 'learning_rate': 0.02103714593728752, 'n_estimators': 600, 'subsample': 0.9309051199347205, 'colsample_bytree': 0.5026230944189093}.\n",
            "[I 2025-02-09 06:31:35,542] Trial 15 finished with values: [0.0947830251458392, 0.5624085485704372] and parameters: {'max_depth': 6, 'learning_rate': 0.0145426165797802, 'n_estimators': 400, 'subsample': 0.7164646676125994, 'colsample_bytree': 0.8174012926063465}.\n",
            "[I 2025-02-09 06:32:23,128] Trial 16 finished with values: [0.08712427057061785, 0.5545368305913646] and parameters: {'max_depth': 5, 'learning_rate': 0.23031172406531691, 'n_estimators': 950, 'subsample': 0.9507409427681426, 'colsample_bytree': 0.8184342556998473}.\n",
            "[I 2025-02-09 06:32:48,875] Trial 17 finished with values: [0.09226550402272025, 0.5593476355129313] and parameters: {'max_depth': 4, 'learning_rate': 0.10056698077388045, 'n_estimators': 550, 'subsample': 0.8346933299479629, 'colsample_bytree': 0.6990364263457693}.\n",
            "[I 2025-02-09 06:33:44,507] Trial 18 finished with values: [0.09302224159218171, 0.5610421529892171] and parameters: {'max_depth': 8, 'learning_rate': 0.02460137597477024, 'n_estimators': 700, 'subsample': 0.9057656842574145, 'colsample_bytree': 0.674193395062148}.\n",
            "[I 2025-02-09 06:34:05,205] Trial 19 finished with values: [0.09358916783455007, 0.5584908822908523] and parameters: {'max_depth': 3, 'learning_rate': 0.0318100867627122, 'n_estimators': 500, 'subsample': 0.681379502182405, 'colsample_bytree': 0.8475549737603898}.\n",
            "[I 2025-02-09 06:34:58,072] Trial 20 finished with values: [0.09258232261869014, 0.5616887081699301] and parameters: {'max_depth': 5, 'learning_rate': 0.04145786455308145, 'n_estimators': 1000, 'subsample': 0.7698506962211981, 'colsample_bytree': 0.6684268732229193}.\n",
            "[I 2025-02-09 06:36:01,531] Trial 21 finished with values: [0.09272925649815084, 0.5600700451154229] and parameters: {'max_depth': 7, 'learning_rate': 0.02261428665508331, 'n_estimators': 950, 'subsample': 0.8884796635737127, 'colsample_bytree': 0.8635277616193535}.\n",
            "[I 2025-02-09 06:36:36,969] Trial 22 finished with values: [0.08964310934920072, 0.5557145434729371] and parameters: {'max_depth': 6, 'learning_rate': 0.13391938544939042, 'n_estimators': 550, 'subsample': 0.8515428127115627, 'colsample_bytree': 0.6087314155685355}.\n",
            "[I 2025-02-09 06:36:43,751] Trial 23 finished with values: [0.09143604086003454, 0.5597217655986769] and parameters: {'max_depth': 5, 'learning_rate': 0.2789243687396094, 'n_estimators': 100, 'subsample': 0.7872207048509716, 'colsample_bytree': 0.6863270654401008}.\n",
            "[I 2025-02-09 06:37:13,839] Trial 24 finished with values: [0.09294650199702792, 0.561496273423065] and parameters: {'max_depth': 7, 'learning_rate': 0.041337461531074725, 'n_estimators': 400, 'subsample': 0.5585683098761042, 'colsample_bytree': 0.5623085914761168}.\n",
            "[I 2025-02-09 06:39:02,643] Trial 25 finished with values: [0.08860380681967567, 0.5465876578723203] and parameters: {'max_depth': 10, 'learning_rate': 0.03787952374444432, 'n_estimators': 1000, 'subsample': 0.656273498255932, 'colsample_bytree': 0.9195045911403401}.\n",
            "[I 2025-02-09 06:39:28,314] Trial 26 finished with values: [0.09486894257354687, 0.5646142297517113] and parameters: {'max_depth': 7, 'learning_rate': 0.01971773831839937, 'n_estimators': 350, 'subsample': 0.9249600255816903, 'colsample_bytree': 0.9541738077880666}.\n",
            "[I 2025-02-09 06:40:04,903] Trial 27 finished with values: [0.09426445500517273, 0.5619489785309325] and parameters: {'max_depth': 5, 'learning_rate': 0.017484299989849097, 'n_estimators': 700, 'subsample': 0.7715668678621641, 'colsample_bytree': 0.6202870927688233}.\n",
            "[I 2025-02-09 06:40:28,829] Trial 28 finished with values: [0.08535378954261548, 0.5420619973237387] and parameters: {'max_depth': 10, 'learning_rate': 0.28291503007208535, 'n_estimators': 200, 'subsample': 0.6375766647170558, 'colsample_bytree': 0.9433750283538549}.\n",
            "[I 2025-02-09 06:41:01,381] Trial 29 finished with values: [0.093480211144226, 0.563232439150123] and parameters: {'max_depth': 6, 'learning_rate': 0.03907902924319736, 'n_estimators': 550, 'subsample': 0.9551973176270987, 'colsample_bytree': 0.9290998213036935}.\n",
            "[I 2025-02-09 06:41:32,857] Trial 30 finished with values: [0.092900511252108, 0.5607164248209945] and parameters: {'max_depth': 8, 'learning_rate': 0.04225072879890454, 'n_estimators': 400, 'subsample': 0.9659726396265467, 'colsample_bytree': 0.8506960729488218}.\n",
            "[I 2025-02-09 06:43:09,547] Trial 31 finished with values: [0.08819524916894995, 0.5464196948133769] and parameters: {'max_depth': 10, 'learning_rate': 0.0557278151080712, 'n_estimators': 900, 'subsample': 0.7567832094333329, 'colsample_bytree': 0.7163064890369664}.\n",
            "[I 2025-02-09 06:44:06,568] Trial 32 finished with values: [0.08622148678914711, 0.5474504723421482] and parameters: {'max_depth': 8, 'learning_rate': 0.19847109958340842, 'n_estimators': 700, 'subsample': 0.8367302506482344, 'colsample_bytree': 0.6024734055379413}.\n",
            "[I 2025-02-09 06:45:17,338] Trial 33 finished with values: [0.08587236616379512, 0.54629367317315] and parameters: {'max_depth': 7, 'learning_rate': 0.12605995260352318, 'n_estimators': 1000, 'subsample': 0.7161264245389247, 'colsample_bytree': 0.8181267295903161}.\n",
            "[I 2025-02-09 06:45:45,926] Trial 34 finished with values: [0.09140010758675336, 0.5595184862115778] and parameters: {'max_depth': 4, 'learning_rate': 0.12052780281034535, 'n_estimators': 600, 'subsample': 0.6480874759954629, 'colsample_bytree': 0.7494852281037045}.\n",
            "[I 2025-02-09 06:46:32,991] Trial 35 finished with values: [0.09100557144601178, 0.5530508558600862] and parameters: {'max_depth': 10, 'learning_rate': 0.031020858803066608, 'n_estimators': 450, 'subsample': 0.7124620592565425, 'colsample_bytree': 0.9073257789421769}.\n",
            "[I 2025-02-09 06:46:54,945] Trial 36 finished with values: [0.09200786022164127, 0.5588751266706088] and parameters: {'max_depth': 3, 'learning_rate': 0.11635257783978474, 'n_estimators': 500, 'subsample': 0.5519987727643423, 'colsample_bytree': 0.915619770629491}.\n",
            "[I 2025-02-09 06:47:32,455] Trial 37 finished with values: [0.0887881877076556, 0.5529873425530097] and parameters: {'max_depth': 7, 'learning_rate': 0.08972623917512784, 'n_estimators': 550, 'subsample': 0.7949989862877747, 'colsample_bytree': 0.9494825507820709}.\n",
            "[I 2025-02-09 06:47:41,740] Trial 38 finished with values: [0.091562309057929, 0.5604642585414469] and parameters: {'max_depth': 6, 'learning_rate': 0.199509839358786, 'n_estimators': 100, 'subsample': 0.6112554319018115, 'colsample_bytree': 0.6460964999782635}.\n",
            "[I 2025-02-09 06:48:22,934] Trial 39 finished with values: [0.09309693027127701, 0.5586163409523864] and parameters: {'max_depth': 10, 'learning_rate': 0.022142996737616088, 'n_estimators': 400, 'subsample': 0.8851752318284715, 'colsample_bytree': 0.8373575655065436}.\n",
            "[I 2025-02-09 06:49:56,809] Trial 40 finished with values: [0.08754360725482026, 0.5454565560144481] and parameters: {'max_depth': 9, 'learning_rate': 0.06143794310856552, 'n_estimators': 1000, 'subsample': 0.6752530687772503, 'colsample_bytree': 0.9850468856419179}.\n",
            "[I 2025-02-09 06:50:52,700] Trial 41 finished with values: [0.08964937026614338, 0.5550164010869604] and parameters: {'max_depth': 6, 'learning_rate': 0.07153406465515019, 'n_estimators': 950, 'subsample': 0.871554374757866, 'colsample_bytree': 0.9983308812188741}.\n",
            "[I 2025-02-09 06:51:40,826] Trial 42 finished with values: [0.08657830994274048, 0.5493552229000265] and parameters: {'max_depth': 7, 'learning_rate': 0.10956176136159876, 'n_estimators': 650, 'subsample': 0.5100933341145442, 'colsample_bytree': 0.9190952356145088}.\n",
            "[I 2025-02-09 06:51:50,433] Trial 43 finished with values: [0.09440875969627897, 0.5580405856581813] and parameters: {'max_depth': 5, 'learning_rate': 0.012643752137111544, 'n_estimators': 150, 'subsample': 0.8370325951854061, 'colsample_bytree': 0.949927198496122}.\n",
            "[I 2025-02-09 06:52:10,637] Trial 44 finished with values: [0.09335595048479217, 0.5612505987065847] and parameters: {'max_depth': 7, 'learning_rate': 0.043501753603278605, 'n_estimators': 250, 'subsample': 0.735181751357202, 'colsample_bytree': 0.7759591480046488}.\n",
            "[I 2025-02-09 06:52:57,549] Trial 45 finished with values: [0.08930266257451606, 0.5563405498246188] and parameters: {'max_depth': 4, 'learning_rate': 0.14823151707738652, 'n_estimators': 1000, 'subsample': 0.6666566867552939, 'colsample_bytree': 0.8219939160524513}.\n",
            "[I 2025-02-09 06:53:06,344] Trial 46 finished with values: [0.09442556862209107, 0.5579594556641234] and parameters: {'max_depth': 5, 'learning_rate': 0.01244118610763757, 'n_estimators': 100, 'subsample': 0.8094468535705777, 'colsample_bytree': 0.5204504519339936}.\n",
            "[I 2025-02-09 06:53:58,850] Trial 47 finished with values: [0.09388755571824803, 0.5625974062245075] and parameters: {'max_depth': 7, 'learning_rate': 0.017121672389829316, 'n_estimators': 800, 'subsample': 0.8877109591310985, 'colsample_bytree': 0.758094627138525}.\n",
            "[I 2025-02-09 06:54:37,227] Trial 48 finished with values: [0.08508821264005793, 0.5471443719153734] and parameters: {'max_depth': 7, 'learning_rate': 0.2380924544549956, 'n_estimators': 500, 'subsample': 0.7178514594424084, 'colsample_bytree': 0.9437141826666123}.\n",
            "[I 2025-02-09 06:54:47,653] Trial 49 finished with values: [0.0927394528749138, 0.5559398293791743] and parameters: {'max_depth': 3, 'learning_rate': 0.025167397235090514, 'n_estimators': 200, 'subsample': 0.8284911466813042, 'colsample_bytree': 0.7119732184145097}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trials:  50\n",
            "Pareto front of best trials:\n",
            "  Values (PR-AUC, BA): [0.09520251897750738, 0.5627427173702726], Params: {'max_depth': 7, 'learning_rate': 0.013300952811159497, 'n_estimators': 250, 'subsample': 0.703613432745979, 'colsample_bytree': 0.6988061156553222}\n",
            "  Values (PR-AUC, BA): [0.09486894257354687, 0.5646142297517113], Params: {'max_depth': 7, 'learning_rate': 0.01971773831839937, 'n_estimators': 350, 'subsample': 0.9249600255816903, 'colsample_bytree': 0.9541738077880666}\n",
            "\n",
            "Selected best trial (highest PR-AUC):\n",
            "  Best PR-AUC:  0.09520251897750738\n",
            "  Balanced Accuracy:  0.5627427173702726\n",
            "  Best hyperparameters:  {'max_depth': 7, 'learning_rate': 0.013300952811159497, 'n_estimators': 250, 'subsample': 0.703613432745979, 'colsample_bytree': 0.6988061156553222}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:54:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test predictions (first 10): [1 1 0 1 0 0 1 0 1 0]\n",
            "Test predicted probabilities (first 10): [0.50094336 0.6815851  0.49816588 0.5343206  0.49860415 0.46875662\n",
            " 0.53607    0.4913074  0.66082054 0.4213204 ]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Average Precision (PR-AUC): 0.10852301209148003\n",
            "Validation Balanced Accuracy: 0.5954602379458809\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}